{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOBODY TOUCH THIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from survae import SurVAE\n",
    "from survae.data import *\n",
    "from survae.layer import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPoolingLayerWithHop(Layer):\n",
    "    '''\n",
    "    MaxPoolingLayer: Layer that performs max pooling on the input data.\n",
    "\n",
    "    size: input size, i.e. flattened picture\n",
    "    width: input width, i.e. the width of the picture, sqrt of size\n",
    "    hop: defines the distance between the blocks of size stride for which the maxima is taken\n",
    "        we require that hop >= 1\n",
    "\n",
    "    out_width: width of the output picture, sqrt of out_size\n",
    "    out_size: size of flattened output picture\n",
    "\n",
    "    stride: the stride of the max pooling operation \n",
    "    index_probs: probability distribution for the indices of the local maxima in the \"flattened\" stride square\n",
    "        we assume that the indices are uniformly distributed\n",
    "\n",
    "    Distribution choices: \n",
    "        - standard half-normal distribution (default)\n",
    "        - exponential distribution \n",
    "\n",
    "    '''\n",
    "    def __init__(self, size: int, stride: int, hop: int, exponential_distribution: bool = False, learn_distribution_parameter: bool = False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.size = size\n",
    "\n",
    "        self.width = np.sqrt(size).astype(int) \n",
    "\n",
    "        assert stride <= self.width, \"Stride must be smaller than the width of the picture!\"\n",
    "        assert 0 < hop and hop <= stride, \"Hop must be smaller than the stride!\"\n",
    "        assert (self.width - stride) % hop == 0, \"Stride and hop must be chosen such that the picture is fully covered!\"\n",
    "\n",
    "        self.stride = stride\n",
    "        self.hop = hop\n",
    "\n",
    "        self.out_width = (self.width - stride) // hop + 1 # = the number of blocks considered (possible overlap)\n",
    "\n",
    "        \n",
    "        if exponential_distribution:\n",
    "            self.distribution = \"exponential\"\n",
    "            lam = torch.tensor([0.1])\n",
    "            if learn_distribution_parameter:\n",
    "                lam = nn.Parameter(lam)\n",
    "            self.lam = lam\n",
    "        else:\n",
    "            self.distribution = \"half-normal\"\n",
    "            sigma = 1\n",
    "            if learn_distribution_parameter:\n",
    "                sigma = nn.Parameter(sigma)\n",
    "            self.sigma = sigma\n",
    "\n",
    "\n",
    "        self.index_probs = torch.tensor([1 / self.stride**2 for _ in range(self.stride**2)])\n",
    "\n",
    "\n",
    "    def forward(self, X: torch.Tensor, condition: torch.Tensor | None = None, return_log_likelihood: bool = False):\n",
    "\n",
    "        X = X.view(-1, self.width, self.width) # reshape to 2D\n",
    "        \n",
    "        l = []\n",
    "        for i in range(self.stride):\n",
    "            for j in range(self.stride):\n",
    "                l.append(X[:, i:i+self.width-self.stride + 1:self.hop,j:j+self.width-self.stride + 1:self.hop])\n",
    "                print(l[-1].shape)\n",
    "\n",
    "        combined_tensor = torch.stack(l, dim=0)\n",
    "        Z, _ = torch.max(combined_tensor, dim=0)\n",
    "\n",
    "        return Z.flatten(start_dim=1)\n",
    "    \n",
    "    def backward(self, Z: torch.Tensor, condition: torch.Tensor | None = None):\n",
    "        Z = Z.view(-1, self.out_width, self.out_width)\n",
    "\n",
    "        _max = Z.max() + 1\n",
    "        max_max = torch.full((len(Z), self.out_width * self.out_width, self.width, self.width), _max)\n",
    "\n",
    "        batch_indices = torch.arange(len(Z))\n",
    "        for i in range(self.out_width):\n",
    "            for j in range(self.out_width):\n",
    "                max_max[batch_indices, j + i * (self.out_width), (self.hop * i):(self.hop * i + self.stride), (self.hop * j):(self.hop * j + self.stride)] = Z[batch_indices, i, j].unsqueeze(1).unsqueeze(2)\n",
    "\n",
    "        # This is the best possible name. I will not elaborate.\n",
    "        min_max = max_max.min(dim=1)[0]\n",
    "\n",
    "        block_mask = torch.isclose(min_max.unsqueeze(1), max_max)\n",
    "        _rand = torch.rand(block_mask.shape)\n",
    "        _rand[~block_mask] = -1\n",
    "        arg_max = _rand.flatten(start_dim=2).argmax(dim=2)\n",
    "\n",
    "        noise_mask = torch.ones((len(Z), self.size), dtype=torch.bool)\n",
    "        for idx in arg_max.T:\n",
    "            noise_mask[batch_indices, idx] = False\n",
    "\n",
    "        # sample values in (- infty, 0]) with respective distribution\n",
    "        if self.distribution == \"half-normal\":\n",
    "            distr = torch.distributions.half_normal.HalfNormal(self.sigma)\n",
    "        else:\n",
    "            distr = torch.distributions.exponential.Exponential(self.lam)\n",
    "        samples = -distr.sample(noise_mask.shape)\n",
    "\n",
    "        X_hat = min_max.flatten(start_dim=1) + (samples * noise_mask)\n",
    "\n",
    "        return X_hat\n",
    "\n",
    "    def in_size(self) -> int | None:\n",
    "        return self.size\n",
    "\n",
    "    def out_size(self) -> int | None:\n",
    "        return int(self.out_width ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "stride = 3\n",
    "hop = 2\n",
    "width = 11\n",
    "size = 11 ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.6169e-01, -4.9837e-01, -3.6823e-01, -1.0678e+00,  8.5087e-01,\n",
       "          -1.4756e+00,  1.3415e+00,  9.5072e-01,  7.5384e-01,  4.8031e-01,\n",
       "          -1.6446e+00],\n",
       "         [-1.1954e+00, -2.8456e-01,  9.8753e-01, -2.6220e-02,  4.9732e-01,\n",
       "           1.6501e+00,  7.6097e-01,  6.2538e-01,  1.7338e+00,  1.3753e-01,\n",
       "          -7.4808e-02],\n",
       "         [ 6.1283e-01, -1.3058e+00,  2.9694e-01,  6.0140e-01, -1.3080e+00,\n",
       "           7.7402e-01,  6.8075e-01,  2.1717e+00, -1.6834e-01,  4.5260e-01,\n",
       "          -1.1169e-01],\n",
       "         [ 8.3983e-01, -7.6345e-01,  1.0826e+00, -3.1517e-01,  1.1299e+00,\n",
       "           2.7441e+00, -1.0826e+00,  1.2842e-01, -2.7102e-01, -8.2161e-01,\n",
       "           1.0545e+00],\n",
       "         [ 4.0962e-01,  1.1643e-01, -9.8105e-01, -2.3844e+00, -1.2941e+00,\n",
       "          -7.7962e-02,  9.7388e-02,  1.7634e+00, -2.6357e-01,  1.0084e+00,\n",
       "          -1.7644e-01],\n",
       "         [-9.6454e-01,  1.4662e-01,  1.2819e+00,  7.0117e-02,  1.3592e-01,\n",
       "          -2.2104e-03,  2.5133e+00, -7.7248e-01, -1.4436e+00, -1.0413e+00,\n",
       "          -1.0250e+00],\n",
       "         [-3.6242e-01, -1.4438e-01,  1.1158e+00,  5.2781e-01, -7.6460e-01,\n",
       "           8.6938e-01, -1.0509e+00, -2.9851e-01, -4.9193e-02, -9.3315e-01,\n",
       "          -7.1009e-02],\n",
       "         [-1.6921e-01, -1.1250e+00, -3.0202e-01,  2.1062e-01, -1.5633e+00,\n",
       "          -8.7686e-02,  1.8269e-01,  8.9468e-01, -1.7078e+00,  6.5771e-01,\n",
       "          -7.2112e-01],\n",
       "         [ 3.7072e-01,  1.0573e+00,  7.1713e-01,  2.0937e+00,  1.3797e+00,\n",
       "           1.5041e+00,  7.2260e-01, -1.0318e+00, -6.3622e-01, -8.6258e-01,\n",
       "           2.6472e-01],\n",
       "         [ 4.9820e-01, -4.1447e-01, -7.0165e-01,  9.1251e-02,  1.3661e+00,\n",
       "           2.6838e-01, -3.3983e-01, -4.0231e-01,  4.4798e-01,  8.6593e-01,\n",
       "          -4.0144e-01],\n",
       "         [ 3.9475e-02,  2.5549e+00,  2.7944e-01, -1.8040e-01,  1.3497e+00,\n",
       "          -7.1027e-01,  2.4980e+00, -6.1079e-01, -1.9965e+00,  7.8924e-01,\n",
       "          -2.2464e-01]],\n",
       "\n",
       "        [[ 4.2151e-01, -9.5311e-01,  4.0245e-01, -6.5135e-01, -1.4438e+00,\n",
       "          -1.4014e+00,  5.5167e-01,  2.7788e-01, -1.9732e-01,  1.3273e+00,\n",
       "           1.7011e-01],\n",
       "         [-4.7314e-01, -7.0170e-02, -1.9004e-02, -1.1951e+00,  1.7125e+00,\n",
       "          -1.6587e+00,  2.9560e-01,  2.5798e+00, -8.3848e-01,  1.1867e+00,\n",
       "           7.9957e-01],\n",
       "         [-4.0115e-01, -1.0554e+00,  1.2914e-01,  9.9996e-01, -1.3602e+00,\n",
       "           2.0761e-01, -1.2534e+00, -1.1306e+00, -5.1869e-01,  1.2214e+00,\n",
       "          -4.5909e-01],\n",
       "         [-9.9414e-01, -1.7056e-01, -1.4173e+00, -1.7470e+00,  5.1545e-01,\n",
       "          -1.1679e+00, -1.1675e+00, -5.1923e-01, -3.5157e-02, -7.4645e-01,\n",
       "           3.4819e-01],\n",
       "         [-3.7918e-01,  9.4712e-01, -8.9594e-01, -9.5838e-01, -4.2963e-01,\n",
       "          -8.5500e-01, -3.9290e-01,  7.6389e-01,  1.6228e+00,  2.5062e-01,\n",
       "          -7.3152e-01],\n",
       "         [ 1.3252e-01,  1.9646e+00,  2.5007e-01,  2.5550e-01, -2.5895e-01,\n",
       "           8.9566e-01,  1.1243e+00, -1.0540e-01, -1.8479e-01,  4.8569e-01,\n",
       "          -2.8138e+00],\n",
       "         [ 7.7517e-01,  1.2151e-01,  8.5845e-01,  3.4866e-01,  3.9427e-01,\n",
       "           8.6420e-02, -6.6245e-01, -2.2666e-02,  1.3971e+00, -3.4155e-01,\n",
       "           1.8250e-02],\n",
       "         [-8.3676e-01, -4.5404e-01,  1.1373e-01, -6.7511e-01, -2.1011e-01,\n",
       "          -9.2421e-01, -4.3912e-01, -7.1991e-01, -9.7884e-01,  2.2205e-01,\n",
       "          -5.2471e-01],\n",
       "         [ 3.6832e-01,  8.2141e-01,  3.0091e-01,  1.0452e-01, -8.2707e-01,\n",
       "           9.2327e-01, -2.7096e-01, -4.1339e-01, -1.2654e+00, -1.2939e+00,\n",
       "           1.6894e+00],\n",
       "         [ 2.1647e-01,  7.9289e-01,  5.0945e-01,  4.0121e-01,  6.0667e-01,\n",
       "          -7.4965e-01, -3.2550e-03,  7.1628e-01,  1.0012e+00,  1.4776e+00,\n",
       "          -2.5235e-01],\n",
       "         [-3.3886e-01,  1.6660e+00, -1.8392e-01,  1.0845e-01, -1.7308e+00,\n",
       "          -8.7154e-03,  6.9851e-01,  6.2669e-01, -4.9630e-01, -3.2886e-01,\n",
       "          -1.5524e+00]]], device='cuda:0')"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X = torch.arange((size * 2)).double().reshape(2, size)\n",
    "X = torch.randn(2, size)\n",
    "X.view(-1, width, width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 5, 5])\n",
      "torch.Size([2, 5, 5])\n",
      "torch.Size([2, 5, 5])\n",
      "torch.Size([2, 5, 5])\n",
      "torch.Size([2, 5, 5])\n",
      "torch.Size([2, 5, 5])\n",
      "torch.Size([2, 5, 5])\n",
      "torch.Size([2, 5, 5])\n",
      "torch.Size([2, 5, 5])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.9875, 0.9875, 1.6501, 2.1717, 1.7338, 1.0826, 1.1299, 2.7441, 2.1717,\n",
       "         1.0545, 1.2819, 1.2819, 2.5133, 2.5133, 1.0084, 1.1158, 2.0937, 1.5041,\n",
       "         0.8947, 0.6577, 2.5549, 2.0937, 2.4980, 2.4980, 0.8659],\n",
       "        [0.4215, 1.7125, 1.7125, 2.5798, 1.3273, 0.9471, 1.0000, 0.5154, 1.6228,\n",
       "         1.6228, 1.9646, 0.8585, 1.1243, 1.6228, 1.6228, 0.8585, 0.8585, 0.9233,\n",
       "         1.3971, 1.6894, 1.6660, 0.6067, 0.9233, 1.0012, 1.6894]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = MaxPoolingLayerWithHop(size, stride, hop)\n",
    "Z = M.forward(X)\n",
    "Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.4215, -0.9531,  0.4025, -0.6514, -1.4438, -1.4014,  0.5517,  0.2779,\n",
       "        -0.1973,  1.3273,  0.1701, -0.4731, -0.0702, -0.0190, -1.1951,  1.7125,\n",
       "        -1.6587,  0.2956,  2.5798, -0.8385,  1.1867,  0.7996, -0.4012, -1.0554,\n",
       "         0.1291,  1.0000, -1.3602,  0.2076, -1.2534, -1.1306, -0.5187,  1.2214,\n",
       "        -0.4591, -0.9941, -0.1706, -1.4173, -1.7470,  0.5154, -1.1679, -1.1675,\n",
       "        -0.5192, -0.0352, -0.7464,  0.3482, -0.3792,  0.9471, -0.8959, -0.9584,\n",
       "        -0.4296, -0.8550, -0.3929,  0.7639,  1.6228,  0.2506, -0.7315,  0.1325,\n",
       "         1.9646,  0.2501,  0.2555, -0.2589,  0.8957,  1.1243, -0.1054, -0.1848,\n",
       "         0.4857, -2.8138,  0.7752,  0.1215,  0.8585,  0.3487,  0.3943,  0.0864,\n",
       "        -0.6624, -0.0227,  1.3971, -0.3416,  0.0183, -0.8368, -0.4540,  0.1137,\n",
       "        -0.6751, -0.2101, -0.9242, -0.4391, -0.7199, -0.9788,  0.2221, -0.5247,\n",
       "         0.3683,  0.8214,  0.3009,  0.1045, -0.8271,  0.9233, -0.2710, -0.4134,\n",
       "        -1.2654, -1.2939,  1.6894,  0.2165,  0.7929,  0.5094,  0.4012,  0.6067,\n",
       "        -0.7497, -0.0033,  0.7163,  1.0012,  1.4776, -0.2523, -0.3389,  1.6660,\n",
       "        -0.1839,  0.1085, -1.7308, -0.0087,  0.6985,  0.6267, -0.4963, -0.3289,\n",
       "        -1.5524], device='cuda:0')"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4215, -0.6940, -2.2752, -0.0152,  0.4294,  0.6356,  1.7125,  2.5464,\n",
       "          0.0298,  1.2753,  0.8869],\n",
       "        [ 0.2652,  0.0117,  0.1767,  1.4352,  1.7125, -0.1051,  0.7302,  2.5798,\n",
       "          0.3721,  1.1857,  1.3273],\n",
       "        [-0.0507, -0.8287, -0.1616, -0.2671, -0.0553, -0.1914,  0.5102,  1.2566,\n",
       "          1.0282, -0.4295, -0.1043],\n",
       "        [-0.7745, -0.1292,  0.9471,  1.0000, -0.5373, -1.0983,  0.5154,  0.2941,\n",
       "          0.3589,  1.0686,  1.6228],\n",
       "        [-0.3145,  0.8919,  0.2807,  0.7780, -0.9890, -0.3129, -1.8920,  1.6228,\n",
       "          0.4688, -0.0866,  0.2354],\n",
       "        [ 0.3986,  1.9646,  0.3941,  0.8585,  0.4519, -0.2497,  1.1243,  0.8579,\n",
       "          0.9146,  1.6154,  1.6047],\n",
       "        [ 0.6650,  0.8316,  0.6711, -0.0119,  0.4888,  0.4752,  0.6339,  1.3462,\n",
       "          1.3805,  1.6228,  1.1591],\n",
       "        [ 0.8585,  0.0646, -1.3792,  0.3981,  0.8585,  0.9233,  0.5131,  1.3971,\n",
       "          1.0098,  1.0437,  0.1427],\n",
       "        [ 0.7574,  0.2537, -0.1676, -0.9752,  0.2323,  0.6884,  0.7451,  1.0012,\n",
       "          0.3109,  1.6808,  1.6894],\n",
       "        [ 1.6660,  1.1067,  0.0982,  0.6067, -0.0312,  0.9233,  0.1754,  0.7065,\n",
       "          0.2523,  1.0672,  0.0673],\n",
       "        [ 1.0203,  0.9843,  0.3491, -0.4124, -0.6257, -0.6364,  0.0881,  0.1925,\n",
       "          0.7401,  0.9993,  1.6894]], device='cuda:0')"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_hat = M.backward(Z)\n",
    "X_hat.view(2, 11, 11)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 5, 5])\n",
      "torch.Size([2, 5, 5])\n",
      "torch.Size([2, 5, 5])\n",
      "torch.Size([2, 5, 5])\n",
      "torch.Size([2, 5, 5])\n",
      "torch.Size([2, 5, 5])\n",
      "torch.Size([2, 5, 5])\n",
      "torch.Size([2, 5, 5])\n",
      "torch.Size([2, 5, 5])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.9875, 0.9875, 1.6501, 2.1717, 1.7338, 1.0826, 1.1299, 2.7441, 2.1717,\n",
       "         1.0545, 1.2819, 1.2819, 2.5133, 2.5133, 1.0084, 1.1158, 2.0937, 1.5041,\n",
       "         0.8947, 0.6577, 2.5549, 2.0937, 2.4980, 2.4980, 0.8659],\n",
       "        [0.4215, 1.7125, 1.7125, 2.5798, 1.3273, 0.9471, 1.0000, 0.5154, 1.6228,\n",
       "         1.6228, 1.9646, 0.8585, 1.1243, 1.6228, 1.6228, 0.8585, 0.8585, 0.9233,\n",
       "         1.3971, 1.6894, 1.6660, 0.6067, 0.9233, 1.0012, 1.6894]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z_hat = M.forward(X_hat)\n",
    "Z_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9875, 0.9875, 1.6501, 2.1717, 1.7338, 1.0826, 1.1299, 2.7441, 2.1717,\n",
       "         1.0545, 1.2819, 1.2819, 2.5133, 2.5133, 1.0084, 1.1158, 2.0937, 1.5041,\n",
       "         0.8947, 0.6577, 2.5549, 2.0937, 2.4980, 2.4980, 0.8659],\n",
       "        [0.4215, 1.7125, 1.7125, 2.5798, 1.3273, 0.9471, 1.0000, 0.5154, 1.6228,\n",
       "         1.6228, 1.9646, 0.8585, 1.1243, 1.6228, 1.6228, 0.8585, 0.8585, 0.9233,\n",
       "         1.3971, 1.6894, 1.6660, 0.6067, 0.9233, 1.0012, 1.6894]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 24.0000,  23.5045,  23.5058,  26.0000,  24.3403,  27.9868,  27.8526,\n",
       "          28.7478,  29.9449,  31.4097,  31.2622],\n",
       "        [ 23.6969,  23.9655,  22.4380,  25.7051,  25.5659,  28.0000,  26.5468,\n",
       "          28.8559,  28.7481,  31.6039,  31.9620],\n",
       "        [ 23.5923,  23.9763,  23.4521,  24.7231,  25.4507,  25.9755,  27.6326,\n",
       "          29.3905,  30.0000,  31.7688,  32.0000],\n",
       "        [ 45.0696,  45.8001,  45.6782,  48.0000,  47.9187,  50.0000,  48.7045,\n",
       "          51.2083,  52.0000,  51.6875,  53.5254],\n",
       "        [ 46.0000,  45.7557,  45.9206,  47.8226,  47.9991,  49.0587,  48.3122,\n",
       "          50.9986,  51.3033,  53.6216,  54.0000],\n",
       "        [ 67.9560,  67.0166,  67.4944,  69.5665,  69.8349,  71.9635,  69.9864,\n",
       "          73.0992,  72.8426,  73.5723,  75.9999],\n",
       "        [ 68.0000,  66.8994,  66.9654,  70.0000,  68.1620,  70.6817,  72.0000,\n",
       "          73.2720,  74.0000,  76.0000,  75.0762],\n",
       "        [ 87.2095,  89.9965,  89.9415,  92.0000,  91.2262,  94.0000,  93.2638,\n",
       "          95.4544,  94.5685,  96.4376,  97.9747],\n",
       "        [ 90.0000,  88.9447,  89.6342,  91.7805,  91.0753,  93.0952,  92.1776,\n",
       "          96.0000,  95.7030,  98.0000,  96.1317],\n",
       "        [110.9716, 112.0000, 110.7760, 112.9716, 113.6260, 116.0000, 114.9064,\n",
       "         117.9134, 118.0000, 119.5128, 118.4332],\n",
       "        [111.6486, 110.2036, 111.7874, 112.7345, 114.0000, 115.6602, 115.3045,\n",
       "         115.7759, 116.9647, 120.0000, 118.9303]], device='cuda:0')"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_hat_hat = M.backward(Z_hat)\n",
    "X_hat_hat.view(2, 11, 11)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "_max = Z.max() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = MaxPoolingLayer(18*18, 3)\n",
    "Z = torch.rand(300, 6*6) * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = N.backward(Z)\n",
    "Z_tilde = N.forward(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(Z, Z_tilde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tilde = Z.view(-1, 6, 6).repeat_interleave(3, dim=2).repeat_interleave(3, dim=1).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.0187, 1.5905, 1.4425,  ..., 0.1042, 0.5838, 0.9130],\n",
       "        [1.8340, 0.8886, 2.1207,  ..., 0.9819, 1.3652, 1.3764],\n",
       "        [2.1103, 2.0345, 1.8622,  ..., 1.8676, 0.1135, 1.0842],\n",
       "        ...,\n",
       "        [0.8945, 0.2138, 0.4180,  ..., 1.0716, 2.7263, 1.3650],\n",
       "        [0.4388, 0.1131, 1.9491,  ..., 1.5017, 1.8399, 0.9055],\n",
       "        [1.2034, 0.8644, 0.8090,  ..., 0.7842, 2.2281, 1.2368]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z_tilde_tilde = N.forward(X_tilde)\n",
    "Z_tilde_tilde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(Z, Z_tilde_tilde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "stride = 3\n",
    "hop = 2\n",
    "width = 11\n",
    "size = 11 ** 2\n",
    "out_width = (width - stride) // hop + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 24.,  26.,  28.,  30.,  32.],\n",
       "         [ 46.,  48.,  50.,  52.,  54.],\n",
       "         [ 68.,  70.,  72.,  74.,  76.],\n",
       "         [ 90.,  92.,  94.,  96.,  98.],\n",
       "         [112., 114., 116., 118., 120.]],\n",
       "\n",
       "        [[145., 147., 149., 151., 153.],\n",
       "         [167., 169., 171., 173., 175.],\n",
       "         [189., 191., 193., 195., 197.],\n",
       "         [211., 213., 215., 217., 219.],\n",
       "         [233., 235., 237., 239., 241.]]], device='cuda:0')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z = Z.view(-1, out_width, out_width)\n",
    "Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_masks = torch.full((2, out_width * out_width, width, width), _max)\n",
    "\n",
    "batch_indices = torch.arange(len(Z))\n",
    "for i in range(out_width):\n",
    "    for j in range(out_width):\n",
    "        max_masks[batch_indices, j + i * (out_width), (hop * i):(hop * i + stride), (hop * j):(hop * j + stride)] = Z[batch_indices, i, j].unsqueeze(1).unsqueeze(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[242., 242., 242., 242., 242., 242., 242., 242., 242., 242., 242.],\n",
       "        [242., 242., 242., 242., 242., 242., 242., 242., 242., 242., 242.],\n",
       "        [242., 242.,  48.,  48.,  48., 242., 242., 242., 242., 242., 242.],\n",
       "        [242., 242.,  48.,  48.,  48., 242., 242., 242., 242., 242., 242.],\n",
       "        [242., 242.,  48.,  48.,  48., 242., 242., 242., 242., 242., 242.],\n",
       "        [242., 242., 242., 242., 242., 242., 242., 242., 242., 242., 242.],\n",
       "        [242., 242., 242., 242., 242., 242., 242., 242., 242., 242., 242.],\n",
       "        [242., 242., 242., 242., 242., 242., 242., 242., 242., 242., 242.],\n",
       "        [242., 242., 242., 242., 242., 242., 242., 242., 242., 242., 242.],\n",
       "        [242., 242., 242., 242., 242., 242., 242., 242., 242., 242., 242.],\n",
       "        [242., 242., 242., 242., 242., 242., 242., 242., 242., 242., 242.]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_masks[0, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 24.,  24.,  24.,  26.,  26.,  28.,  28.,  30.,  30.,  32.,  32.],\n",
       "         [ 24.,  24.,  24.,  26.,  26.,  28.,  28.,  30.,  30.,  32.,  32.],\n",
       "         [ 24.,  24.,  24.,  26.,  26.,  28.,  28.,  30.,  30.,  32.,  32.],\n",
       "         [ 46.,  46.,  46.,  48.,  48.,  50.,  50.,  52.,  52.,  54.,  54.],\n",
       "         [ 46.,  46.,  46.,  48.,  48.,  50.,  50.,  52.,  52.,  54.,  54.],\n",
       "         [ 68.,  68.,  68.,  70.,  70.,  72.,  72.,  74.,  74.,  76.,  76.],\n",
       "         [ 68.,  68.,  68.,  70.,  70.,  72.,  72.,  74.,  74.,  76.,  76.],\n",
       "         [ 90.,  90.,  90.,  92.,  92.,  94.,  94.,  96.,  96.,  98.,  98.],\n",
       "         [ 90.,  90.,  90.,  92.,  92.,  94.,  94.,  96.,  96.,  98.,  98.],\n",
       "         [112., 112., 112., 114., 114., 116., 116., 118., 118., 120., 120.],\n",
       "         [112., 112., 112., 114., 114., 116., 116., 118., 118., 120., 120.]],\n",
       "\n",
       "        [[145., 145., 145., 147., 147., 149., 149., 151., 151., 153., 153.],\n",
       "         [145., 145., 145., 147., 147., 149., 149., 151., 151., 153., 153.],\n",
       "         [145., 145., 145., 147., 147., 149., 149., 151., 151., 153., 153.],\n",
       "         [167., 167., 167., 169., 169., 171., 171., 173., 173., 175., 175.],\n",
       "         [167., 167., 167., 169., 169., 171., 171., 173., 173., 175., 175.],\n",
       "         [189., 189., 189., 191., 191., 193., 193., 195., 195., 197., 197.],\n",
       "         [189., 189., 189., 191., 191., 193., 193., 195., 195., 197., 197.],\n",
       "         [211., 211., 211., 213., 213., 215., 215., 217., 217., 219., 219.],\n",
       "         [211., 211., 211., 213., 213., 215., 215., 217., 217., 219., 219.],\n",
       "         [233., 233., 233., 235., 235., 237., 237., 239., 239., 241., 241.],\n",
       "         [233., 233., 233., 235., 235., 237., 237., 239., 239., 241., 241.]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_matrix = max_masks.min(dim=1)[0]\n",
    "min_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 25, 11, 11])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 11, 11])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_mask = torch.isclose(min_matrix.unsqueeze(1), max_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "_rand = torch.rand(block_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "_rand[~block_mask] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 12,  25,   6,  19,   9,  33,  37,  38,  40,  54,  68,  69,  71,  74,\n",
       "          65,  78,  80,  82,  96,  86, 110, 103, 105, 107, 109],\n",
       "        [  2,   3,  28,   7,  20,  46,  48,  39,  52,  53,  55,  70,  61,  63,\n",
       "          76,  90,  80,  94,  95,  87, 101, 103, 115, 118, 108]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_argmax = _rand.flatten(start_dim=2).argmax(dim=2)\n",
    "_argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_mask = torch.ones((2, 11 * 11), dtype=torch.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_indices = torch.arange(len(Z))\n",
    "for idx in _argmax.T:\n",
    "    noise_mask[batch_indices, idx] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ True,  True,  True,  True,  True,  True, False,  True,  True, False,\n",
       "           True],\n",
       "         [ True, False,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "           True],\n",
       "         [ True,  True,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "           True],\n",
       "         [False,  True,  True,  True, False, False,  True, False,  True,  True,\n",
       "           True],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          False],\n",
       "         [ True,  True, False, False,  True, False,  True,  True, False,  True,\n",
       "           True],\n",
       "         [ True, False,  True, False,  True, False,  True,  True,  True, False,\n",
       "           True],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "           True],\n",
       "         [ True,  True,  True,  True, False,  True, False,  True, False,  True,\n",
       "          False],\n",
       "         [False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True]],\n",
       "\n",
       "        [[ True,  True, False, False,  True,  True,  True, False,  True,  True,\n",
       "           True],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "           True],\n",
       "         [ True,  True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "           True],\n",
       "         [ True,  True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "           True],\n",
       "         [ True,  True, False,  True, False,  True,  True,  True, False, False,\n",
       "           True],\n",
       "         [False,  True,  True,  True,  True,  True, False,  True, False,  True,\n",
       "           True],\n",
       "         [ True,  True,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "          False],\n",
       "         [ True,  True,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "          False],\n",
       "         [ True,  True, False,  True,  True,  True, False, False,  True,  True,\n",
       "           True],\n",
       "         [ True,  True, False,  True, False,  True,  True,  True,  True, False,\n",
       "           True],\n",
       "         [ True,  True,  True,  True,  True, False,  True,  True, False,  True,\n",
       "           True]]], device='cuda:0')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise_mask.reshape(2, 11, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "distr = torch.distributions.half_normal.HalfNormal(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = -distr.sample(noise_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 24.,  24.,  24.,  26.,  26.,  28.,  28.,  30.,  30.,  32.,  32.,  24.,\n",
       "          24.,  24.,  26.,  26.,  28.,  28.,  30.,  30.,  32.,  32.,  24.,  24.,\n",
       "          24.,  26.,  26.,  28.,  28.,  30.,  30.,  32.,  32.,  46.,  46.,  46.,\n",
       "          48.,  48.,  50.,  50.,  52.,  52.,  54.,  54.,  46.,  46.,  46.,  48.,\n",
       "          48.,  50.,  50.,  52.,  52.,  54.,  54.,  68.,  68.,  68.,  70.,  70.,\n",
       "          72.,  72.,  74.,  74.,  76.,  76.,  68.,  68.,  68.,  70.,  70.,  72.,\n",
       "          72.,  74.,  74.,  76.,  76.,  90.,  90.,  90.,  92.,  92.,  94.,  94.,\n",
       "          96.,  96.,  98.,  98.,  90.,  90.,  90.,  92.,  92.,  94.,  94.,  96.,\n",
       "          96.,  98.,  98., 112., 112., 112., 114., 114., 116., 116., 118., 118.,\n",
       "         120., 120., 112., 112., 112., 114., 114., 116., 116., 118., 118., 120.,\n",
       "         120.],\n",
       "        [145., 145., 145., 147., 147., 149., 149., 151., 151., 153., 153., 145.,\n",
       "         145., 145., 147., 147., 149., 149., 151., 151., 153., 153., 145., 145.,\n",
       "         145., 147., 147., 149., 149., 151., 151., 153., 153., 167., 167., 167.,\n",
       "         169., 169., 171., 171., 173., 173., 175., 175., 167., 167., 167., 169.,\n",
       "         169., 171., 171., 173., 173., 175., 175., 189., 189., 189., 191., 191.,\n",
       "         193., 193., 195., 195., 197., 197., 189., 189., 189., 191., 191., 193.,\n",
       "         193., 195., 195., 197., 197., 211., 211., 211., 213., 213., 215., 215.,\n",
       "         217., 217., 219., 219., 211., 211., 211., 213., 213., 215., 215., 217.,\n",
       "         217., 219., 219., 233., 233., 233., 235., 235., 237., 237., 239., 239.,\n",
       "         241., 241., 233., 233., 233., 235., 235., 237., 237., 239., 239., 241.,\n",
       "         241.]], device='cuda:0')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_matrix.flatten(start_dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "output:torch.Tensor = min_matrix.flatten(start_dim=1) + (noise * noise_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 22.1889,  23.2967,  23.7507,  24.5962,  24.6887,  27.6577,  28.0000,\n",
       "           29.2626,  28.4096,  32.0000,  30.7142],\n",
       "         [ 23.2467,  24.0000,  23.9909,  25.7106,  24.5697,  26.4020,  27.4834,\n",
       "           28.7218,  30.0000,  31.3557,  31.2244],\n",
       "         [ 23.0809,  23.9219,  23.2633,  26.0000,  25.0351,  26.8057,  26.6938,\n",
       "           29.5222,  28.4734,  31.9631,  31.4082],\n",
       "         [ 46.0000,  45.9254,  45.8251,  46.0863,  48.0000,  50.0000,  49.7254,\n",
       "           52.0000,  51.5926,  53.7272,  53.6193],\n",
       "         [ 45.0906,  45.4238,  45.5665,  47.6253,  47.3361,  49.4593,  49.1894,\n",
       "           50.3918,  50.9083,  53.8746,  54.0000],\n",
       "         [ 66.4170,  67.4385,  65.6814,  69.5357,  68.5218,  71.3216,  70.1659,\n",
       "           73.3019,  73.8194,  74.3874,  76.0000],\n",
       "         [ 67.9787,  65.7458,  68.0000,  70.0000,  69.8597,  72.0000,  70.0402,\n",
       "           73.2468,  74.0000,  75.2969,  75.7988],\n",
       "         [ 89.3915,  90.0000,  89.3454,  92.0000,  91.2445,  94.0000,  93.5268,\n",
       "           95.1981,  95.0391,  98.0000,  97.6513],\n",
       "         [ 89.7190,  89.6719,  89.8537,  91.9682,  91.4939,  93.2003,  93.9760,\n",
       "           95.0487,  96.0000,  97.7744,  97.6768],\n",
       "         [110.4601, 111.1044, 111.9439, 112.7983, 114.0000, 113.8287, 116.0000,\n",
       "          117.8313, 118.0000, 118.2872, 120.0000],\n",
       "         [112.0000, 111.0481, 110.7456, 113.3319, 113.5061, 115.5824, 115.9070,\n",
       "          117.2136, 116.3613, 119.9591, 118.7961]],\n",
       "\n",
       "        [[144.2004, 143.6039, 145.0000, 147.0000, 145.2321, 148.0295, 147.3861,\n",
       "          151.0000, 150.6946, 151.7169, 152.7641],\n",
       "         [143.9035, 143.7901, 144.0274, 146.6816, 146.4674, 147.8398, 147.9571,\n",
       "          150.9328, 150.3634, 153.0000, 152.9806],\n",
       "         [144.2791, 143.5706, 143.6376, 146.6024, 146.9634, 147.6625, 149.0000,\n",
       "          149.9410, 150.0211, 151.4534, 152.1314],\n",
       "         [166.5966, 165.6856, 166.5331, 168.2839, 168.7469, 170.8311, 171.0000,\n",
       "          171.9681, 172.5171, 174.5079, 174.1529],\n",
       "         [166.5616, 166.0271, 167.0000, 168.8150, 169.0000, 170.8114, 168.7330,\n",
       "          172.7638, 173.0000, 175.0000, 174.1683],\n",
       "         [189.0000, 188.8312, 188.1617, 189.8430, 189.8160, 192.7125, 193.0000,\n",
       "          193.7381, 195.0000, 195.4544, 195.8285],\n",
       "         [187.9996, 188.8430, 187.5780, 190.7497, 191.0000, 191.6405, 191.8872,\n",
       "          193.3741, 194.4141, 196.3530, 197.0000],\n",
       "         [209.2703, 210.0707, 210.0157, 213.0000, 210.2593, 213.5300, 214.8587,\n",
       "          216.8335, 214.8991, 218.9886, 219.0000],\n",
       "         [209.8496, 210.7624, 211.0000, 211.9374, 211.6159, 213.8675, 215.0000,\n",
       "          217.0000, 215.4701, 218.9869, 218.6674],\n",
       "         [232.6637, 232.4840, 233.0000, 234.4811, 235.0000, 236.7371, 236.3243,\n",
       "          237.3049, 238.4235, 241.0000, 240.5176],\n",
       "         [232.3649, 231.5296, 231.2706, 234.6831, 233.6741, 237.0000, 233.3218,\n",
       "          237.7671, 239.0000, 240.5503, 240.4642]]], device='cuda:0')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.view(2, 11, 11)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
