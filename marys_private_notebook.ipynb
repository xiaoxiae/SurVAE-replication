{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOBODY TOUCH THIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from survae import SurVAE\n",
    "from survae.data import *\n",
    "from survae.layer import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPoolingLayerWithHop(Layer):\n",
    "    '''\n",
    "    MaxPoolingLayer: Layer that performs max pooling on the input data.\n",
    "\n",
    "    size: input size, i.e. flattened picture\n",
    "    width: input width, i.e. the width of the picture, sqrt of size\n",
    "    hop: defines the distance between the blocks of size stride for which the maxima is taken\n",
    "        we require that hop >= 1\n",
    "\n",
    "    out_width: width of the output picture, sqrt of out_size\n",
    "    out_size: size of flattened output picture\n",
    "\n",
    "    stride: the stride of the max pooling operation \n",
    "    index_probs: probability distribution for the indices of the local maxima in the \"flattened\" stride square\n",
    "        we assume that the indices are uniformly distributed\n",
    "\n",
    "    Distribution choices: \n",
    "        - standard half-normal distribution (default)\n",
    "        - exponential distribution \n",
    "\n",
    "    '''\n",
    "    def __init__(self, size: int, stride: int, hop: int, exponential_distribution: bool = False, learn_distribution_parameter: bool = False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.size = size\n",
    "\n",
    "        self.width = np.sqrt(size).astype(int) \n",
    "\n",
    "        assert stride <= self.width, \"Stride must be smaller than the width of the picture!\"\n",
    "        assert 0 < hop and hop <= stride, \"Hop must be smaller than the stride!\"\n",
    "        assert (self.width - stride) % hop == 0, \"Stride and hop must be chosen such that the picture is fully covered!\"\n",
    "\n",
    "        self.stride = stride\n",
    "        self.hop = hop\n",
    "\n",
    "        self.out_width = (self.width - stride) // hop + 1 # = the number of blocks considered (possible overlap)\n",
    "\n",
    "        \n",
    "        if exponential_distribution:\n",
    "            self.distribution = \"exponential\"\n",
    "            lam = torch.tensor([0.1])\n",
    "            if learn_distribution_parameter:\n",
    "                lam = nn.Parameter(lam)\n",
    "            self.lam = lam\n",
    "        else:\n",
    "            self.distribution = \"half-normal\"\n",
    "            sigma = 1\n",
    "            if learn_distribution_parameter:\n",
    "                sigma = nn.Parameter(sigma)\n",
    "            self.sigma = sigma\n",
    "\n",
    "\n",
    "        self.index_probs = torch.tensor([1 / self.stride**2 for _ in range(self.stride**2)])\n",
    "\n",
    "\n",
    "    def forward(self, X: torch.Tensor, condition: torch.Tensor | None = None, return_log_likelihood: bool = False):\n",
    "\n",
    "        X = X.view(-1, self.width, self.width) # reshape to 2D\n",
    "        \n",
    "        l = []\n",
    "        for i in range(self.out_width):\n",
    "            for j in range(self.out_width):\n",
    "                l.append(X[:, i * self.hop:i * self.hop + self.stride:,j * self.hop:j * self.hop +self.stride])\n",
    "        print(l)\n",
    "\n",
    "        combined_tensor = torch.stack(l, dim=0)\n",
    "        Z, _ = torch.max(combined_tensor, dim=0)\n",
    "\n",
    "        return Z.flatten(start_dim=1)\n",
    "\n",
    "    def backward(self, Z: torch.Tensor, condition: torch.Tensor | None = None):\n",
    "        Z = Z.view(-1, self.out_width, self.out_width)\n",
    "        \n",
    "        # expand matrix containing local maxima (by repeating local max)\n",
    "        X_hat = Z.repeat_interleave(self.stride,dim=2).repeat_interleave(self.stride,dim=1)\n",
    "\n",
    "        # mask for the indices of the local maxima\n",
    "        k = torch.distributions.categorical.Categorical(self.index_probs) \n",
    "        indices = k.sample(Z.shape)\n",
    "\n",
    "        indices_repeated = indices.repeat_interleave(self.stride, dim=2).repeat_interleave(self.stride, dim=1)\n",
    "        index_places = torch.arange(self.stride**2).reshape(self.stride, self.stride).repeat(self.out_size(), self.out_size())\n",
    "\n",
    "        index_mask = (index_places == indices_repeated)\n",
    "\n",
    "        # sample values in (- infty, 0]) with respective distribution\n",
    "        if self.distribution == \"half-normal\":\n",
    "            distr = torch.distributions.half_normal.HalfNormal(self.sigma)\n",
    "        else:\n",
    "            distr = torch.distributions.exponential.Exponential(self.lam)\n",
    "        samples = -distr.sample(X_hat.shape)\n",
    "\n",
    "        X_hat = X_hat + samples * ~index_mask\n",
    "        \n",
    "        return X_hat.flatten(start_dim=1)\n",
    "\n",
    "    def in_size(self) -> int | None:\n",
    "        return self.size\n",
    "\n",
    "    def out_size(self) -> int | None:\n",
    "        return int(self.out_width ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  0.,   1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.,  10.],\n",
       "         [ 11.,  12.,  13.,  14.,  15.,  16.,  17.,  18.,  19.,  20.,  21.],\n",
       "         [ 22.,  23.,  24.,  25.,  26.,  27.,  28.,  29.,  30.,  31.,  32.],\n",
       "         [ 33.,  34.,  35.,  36.,  37.,  38.,  39.,  40.,  41.,  42.,  43.],\n",
       "         [ 44.,  45.,  46.,  47.,  48.,  49.,  50.,  51.,  52.,  53.,  54.],\n",
       "         [ 55.,  56.,  57.,  58.,  59.,  60.,  61.,  62.,  63.,  64.,  65.],\n",
       "         [ 66.,  67.,  68.,  69.,  70.,  71.,  72.,  73.,  74.,  75.,  76.],\n",
       "         [ 77.,  78.,  79.,  80.,  81.,  82.,  83.,  84.,  85.,  86.,  87.],\n",
       "         [ 88.,  89.,  90.,  91.,  92.,  93.,  94.,  95.,  96.,  97.,  98.],\n",
       "         [ 99., 100., 101., 102., 103., 104., 105., 106., 107., 108., 109.],\n",
       "         [110., 111., 112., 113., 114., 115., 116., 117., 118., 119., 120.]],\n",
       "\n",
       "        [[121., 122., 123., 124., 125., 126., 127., 128., 129., 130., 131.],\n",
       "         [132., 133., 134., 135., 136., 137., 138., 139., 140., 141., 142.],\n",
       "         [143., 144., 145., 146., 147., 148., 149., 150., 151., 152., 153.],\n",
       "         [154., 155., 156., 157., 158., 159., 160., 161., 162., 163., 164.],\n",
       "         [165., 166., 167., 168., 169., 170., 171., 172., 173., 174., 175.],\n",
       "         [176., 177., 178., 179., 180., 181., 182., 183., 184., 185., 186.],\n",
       "         [187., 188., 189., 190., 191., 192., 193., 194., 195., 196., 197.],\n",
       "         [198., 199., 200., 201., 202., 203., 204., 205., 206., 207., 208.],\n",
       "         [209., 210., 211., 212., 213., 214., 215., 216., 217., 218., 219.],\n",
       "         [220., 221., 222., 223., 224., 225., 226., 227., 228., 229., 230.],\n",
       "         [231., 232., 233., 234., 235., 236., 237., 238., 239., 240., 241.]]],\n",
       "       dtype=torch.float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stride = 3\n",
    "hop = 2\n",
    "width = 11\n",
    "size = 11 ** 2\n",
    "X = torch.arange((size * 2)).float().reshape(2, size)\n",
    "X = X.view(-1, width, width)\n",
    "X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 96.,  97.,  98., 107., 108., 109., 118., 119., 120.],\n",
       "        [217., 218., 219., 228., 229., 230., 239., 240., 241.]],\n",
       "       dtype=torch.float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = MaxPoolingLayerWithHop(size, stride, hop)\n",
    "Z = M.forward(X)\n",
    "Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 5, 5])\n",
      "torch.Size([2, 5, 5])\n",
      "torch.Size([2, 5, 5])\n",
      "torch.Size([2, 5, 5])\n",
      "torch.Size([2, 5, 5])\n",
      "torch.Size([2, 5, 5])\n",
      "torch.Size([2, 5, 5])\n",
      "torch.Size([2, 5, 5])\n",
      "torch.Size([2, 5, 5])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 24.,  26.,  28.,  30.,  32.],\n",
       "         [ 46.,  48.,  50.,  52.,  54.],\n",
       "         [ 68.,  70.,  72.,  74.,  76.],\n",
       "         [ 90.,  92.,  94.,  96.,  98.],\n",
       "         [112., 114., 116., 118., 120.]],\n",
       "\n",
       "        [[145., 147., 149., 151., 153.],\n",
       "         [167., 169., 171., 173., 175.],\n",
       "         [189., 191., 193., 195., 197.],\n",
       "         [211., 213., 215., 217., 219.],\n",
       "         [233., 235., 237., 239., 241.]]], dtype=torch.float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_width = (width - stride) // hop + 1\n",
    "l = []\n",
    "for i in range(stride):\n",
    "    for j in range(stride):\n",
    "        l.append(X[:, i:i+width-stride + 2:hop,j:j+width-stride + 2:hop])\n",
    "\n",
    "combined_tensor = torch.stack(l, dim=0)\n",
    "Z, _ = torch.max(combined_tensor, dim=0)\n",
    "Z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
